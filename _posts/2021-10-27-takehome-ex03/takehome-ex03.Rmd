---
title: "Take Home Exercise 03"
description: |
  Building a hedonic pricing models to explain factors affecting the resale prices of Singapore public housing.
author:
  - name: Kwek Yi Chen
    url: https://kwekyichen-is415.netlify.app/posts/2021-10-27-takehome-ex03/
date: 10-27-2021
output:
  distill::distill_article:
    self_contained: false
    toc: true
    toc_float: true
    number_sections: true
    code_folding: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, eval=FALSE)
```


## 1. Introduction



## 2. Setting Up the Environment

### Installing Packages

The following code chunk install the following packages:

dplyr
stringr: stringsub
ggpubr: ggarrange
dummies: create dummy var
olsrr: ols_regress
spdep: dnearneight()

```{r}
packages = c('readr', 'tmap', 'sf', 'onemapsgapi', 'httr', 'dplyr', 'stringr', 'jsonlite', 'tidyr', 'sp', 'dummies', 'geojsonio', 'ggplot2', 'ggpubr', 'GWmodel', 'corrplot', 'olsrr', 'spdep')
for (p in packages){
  if(!require(p, character.only = T)){
    install.packages(p)
    }
  library(p,character.only = T)
}
```

### onemapsgapi Token Authorization

First, we set up the token for onemapsgapi. The code is not shown because the information is sensitive.

```{r echo=FALSE}
token <- "eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJzdWIiOjc5NTMsInVzZXJfaWQiOjc5NTMsImVtYWlsIjoieWljaGVuLmt3ZWsuMjAxOUBzY2lzLnNtdS5lZHUuc2ciLCJmb3JldmVyIjpmYWxzZSwiaXNzIjoiaHR0cDpcL1wvb20yLmRmZS5vbmVtYXAuc2dcL2FwaVwvdjJcL3VzZXJcL3Nlc3Npb24iLCJpYXQiOjE2MzUxMjY5NTcsImV4cCI6MTYzNTU1ODk1NywibmJmIjoxNjM1MTI2OTU3LCJqdGkiOiJmZTAzNzU1OTc4OTI3YWQ5YzY1ZGUwOGE3N2JkYWQ0MCJ9.j9Vy1gwkKjomWfcdVVnUsNjE2OOLze0NJzxplurz-_8"
```

## 3. Data

- HDB Resale Data. It is in csv format from data.gov.sg
- 
- 
-
-

- Note that after data preparation, the state file for run each may be deleted due to Github's file limit.


## 4. Data Preparation

### 4.1 HDB Resales Data

The following code chunk uses read_csv function of readr package to import the hdb resales data and display the data.

```{r eval=FALSE}
hdbresale <- read_csv("data/aspatial/resale-flat-prices-based-on-registration-date-from-jan-2017-onwards.csv")
hdbresale
```

The data contains multiple rows but our focus is only on four-room flat with transaction period from 1st January 2019 to 30th September 2020.

The following code chunk filter the four-room flat data from Jan 2019 to September 2020 using filter function of base package.

Then, we created a new column using mutate function of dplyr package for the following column:

1) address column that combines the block and street name (paste function of base package concatenate the strings, as.character converts the string to character type)
2) story_range_lower and storey_range_upper column that split the storey_range (str_sub function of stringr)
3) remaining_lease_year column from the remaining_lease string (str_sub function of stringr)
4) we selected all the columns
5) display the data.

```{r eval=FALSE}
hdbresale_filtered <- hdbresale %>%
                filter(month %in% c("2019-01", "2019-02", "2019-03", "2019-04", "2019-05", "2019-06", "2019-07", "2019-08", "2019-09", "2019-10", "2019-11", "2019-12","2020-01", "2020-02", "2020-03", "2020-04", "2020-05", "2020-06", "2020-07", "2020-08", "2020-09")) %>%
                filter(flat_type == "4 ROOM")

hdbresale_new <- hdbresale_filtered %>%
                  mutate(hdbresale_filtered, address = paste(as.character(block),as.character(street_name))) %>%
                  mutate(hdbresale_filtered, storey_range_lower = str_sub(storey_range, 0, 2)) %>%
                  mutate(hdbresale_filtered, storey_range_upper = str_sub(storey_range, -3, -1)) %>%
                  mutate(hdbresale_filtered, remaining_lease_year = str_sub(remaining_lease, 0, 2)) %>%
                  select(month, town, address, block, street_name, flat_type, storey_range, storey_range_lower, storey_range_upper, floor_area_sqm, flat_model, lease_commence_date, remaining_lease, remaining_lease_year, resale_price)

hdbresale_new
```

We can see that from Jan 2019 to September 2020, there are 15901 transactions for four-room flat in Singapore.

Get lat long with address

The follow code chunk:

1) iterate through every rows of data in hdbresale_new table
2) for each row, we will get the address and set the onemapsgapi url
3) we will next get encode the url with URLencode function
4) get the result of the encode_url with GET function of httr package
5) extract the content from the getcoordinate request. as argument is set as "parsed"
6) if there are at least one result, we extract the latitude and longitude and assign it to the column respectively


```{r eval=FALSE}
for (i in 1:nrow(hdbresale_new)) {
  address <- hdbresale_new[i,'address']
  
  url = paste('https://developers.onemap.sg/commonapi/search?searchVal=', address, '&returnGeom=Y&getAddrDetails=Y&pageNum=1')
  encoded_url <- URLencode(url)
  
  getcoordinate <- GET(encoded_url)
  
  jsonParsed <- content(getcoordinate,as="parsed")
  
  if (length(jsonParsed$results) > 0) {
    hdbresale_new[i,'LATITUDE'] = jsonParsed$results[[1]]$LATITUDE
    hdbresale_new[i,'LONGITUDE'] = jsonParsed$results[[1]]$LONGITUDE
  }
}
```

Check if any rows with missing lat long

The following code chunk use is.na function of base package and sum to calculate the total number of NA is there is any.

```{r eval=FALSE}
sum(is.na(hdbresale_new$LATITUDE))
```

There are 26 rows with missing lat long. We will take a look at which areas are the affected rows

The following code chunk filters the rows with missing latlong 

```{r eval=FALSE}
hdbresaleNA <- hdbresale_new %>%
                 filter(is.na(hdbresale_new$LATITUDE))
hdbresaleNA
```

From the above, we can see that the common location with missing lat long is ST. GEORGE. 

We will next assign the lat long to these rows as long as the address is "ST. GEORGE" if there are any result

Similar to previous, this time we set the address as default "ST.GEORGE" and assign to each row as long as there is result

```{r eval=FALSE}
for (i in 1:nrow(hdbresaleNA)) {
  address = "ST. GEORGE"
  url = paste('https://developers.onemap.sg/commonapi/search?searchVal=', address, '&returnGeom=Y&getAddrDetails=Y&pageNum=1')
  encoded_url <- URLencode(url)
  
  getcoordinate <- GET(encoded_url)
  
  jsonParsed <- content(getcoordinate,as="parsed")
  
  if (length(jsonParsed$results) > 0) {
    hdbresaleNA[i,'LATITUDE'] = jsonParsed$results[[1]]$LATITUDE
    hdbresaleNA[i,'LONGITUDE'] = jsonParsed$results[[1]]$LONGITUDE
  }
}
```

The following code chunk check if there are still any missing value

```{r eval=FALSE}
hdbresaleNA
```

There are no missing value. However, the lat long for the 26 points are all the same.

In order to avoid having overlapping points, we use jitter function so that the lat long are distinct

```{r eval=FALSE}
hdbresaleNA$LATITUDE <- jitter(as.numeric(hdbresaleNA$LATITUDE), factor = 0.00123)
hdbresaleNA$LONGITUDE <- jitter(as.numeric(hdbresaleNA$LONGITUDE), factor = 0.00123)
```

Check the data again

```{r eval=FALSE}
hdbresaleNA
```

We can see that the lat long are different.

The following code chunk filters the rows with latlong using drop_na function of tidyr to drop rows with missing LATITUDE values

```{r eval=FALSE}
hdbresaleNOTNA <- hdbresale_new %>%
                      drop_na(LATITUDE)
hdbresaleNOTNA
```

The following code chunk combines hdbresaleNA and hdbresaleNOTNA using rbind function of base package.

```{r eval=FALSE}
hdbresale_latlong <- rbind(hdbresaleNA, hdbresaleNOTNA)
glimpse(hdbresale_latlong)
```

We have 15901 rows which is same as the number of rows of the initial dataset. 

The following code chunk converts the dataset with latlong decimal degree to metres coordinates, and transform the crs to Singapore's projection, 3414.

```{r eval=FALSE}
hdbresale_latlongm <- st_as_sf(hdbresale_latlong,
                    coords = c("LONGITUDE", 
                               "LATITUDE"),
                    crs=4326) %>%
  st_transform(crs = 3414)
```

The following code chunk plots the points to see if the data is correct using functions of tmap package.

```{r eval=FALSE}
tmap_mode("view")
tm_shape(hdbresale_latlongm)+
  tm_dots()
tmap_mode("plot")
```

Export as csv

The following code chunk export data with sf as csv so that we do not have to re-run the time-consuming process above again.

```{r eval=FALSE}
write.csv(hdbresale_latlong, "data/newaspatial/hdbresale_latlongonly.csv", row.names = FALSE)
```

Import hdbresales csv with Latlong, and convert to singapore crs.

```{r eval=FALSE}
hdbresale_latlononly <- read_csv("data/newaspatial/hdbresale_latlongonly.csv")

hdbresale_latlongtogeo <- st_as_sf(hdbresale_latlononly,
                    coords = c("LONGITUDE", 
                               "LATITUDE"),
                    crs=4326) %>%
  st_transform(crs = 3414)
```

The following code chunk plots the points to check if the imported data is plotted correctly. 

```{r eval=FALSE}
tmap_mode("view")
tm_shape(hdbresale_latlongtogeo)+
  tm_dots()
tmap_mode("plot")
```

### 4.2 Proximity to CBD

Since CBD is a huge area, we will first define the lat long for CBD, taken from Google. (Latitude : 1.2801, Longitude : 103.8509)

The following code chunk:
1) iterate through every single rows in the data
2) the start lat long, end lat long and the routeType are defined. In this analysis, we will be using routeType "drive"
3) the url will be set and the space in url will be removed using gsub function of base package
4) get the result of the url with GET function of httr package
5) extract the content from the getproximitytocdb request. as argument is set as "parsed"
6) if there are at least one result, we extract the total distance, convert it to km by dividing it by 1000, and assign it to the PROX_CBD column.

This process repeated a few times. This is because the onemapsgapi may return NA value for certain rows due to the request limit. Note that the first data was hdbresale_latlononly, and it was replaced by the current hdbresale_latlononly_CBD_NA_2 because of the repetition of this process.

```{r eval=FALSE}
for (i in 1:nrow(hdbresale_latlononly_CBD_NA3)) {
  startlat <- hdbresale_latlononly_CBD_NA3[i,'LATITUDE']
  startlong <- hdbresale_latlononly_CBD_NA3[i,'LONGITUDE']
  
  start = gsub(' ', '', paste(startlat, ',',  startlong))
  
  end = '1.2801,103.8509'
  routeType = 'drive'
  
  url = gsub(' ', '', paste('https://developers.onemap.sg/privateapi/routingsvc/route?start=', start, '&end=', end, '&routeType=', routeType, '&token=', token))
  
  getproximitytocbd <- GET(url)
  
  jsonParsed <- content(getproximitytocbd,as="parsed")
  
  if (length(jsonParsed$route_summary) > 0) {
    hdbresale_latlononly_CBD_NA3[i,'PROX_CBD'] = jsonParsed$route_summary$total_distance/1000
  }
}
```

The following code chunk write a copy of the csv as of the run state. 

```{r eval=FALSE}
write.csv(hdbresale_latlononly_CBD_NA3, "data/newaspatial/hdbresale_PROXCBD_fifthrun.csv", row.names = FALSE)
```

The following code chunk filter the rows with distance NA, and repeat the above code chunk to obtain distance for remaining rows with NA value.

```{r eval=FALSE}
hdbresale_latlononly_CBD_NA4 <- hdbresale_latlononly_CBD_NA3 %>%
                              filter(is.na(hdbresale_latlononly_CBD_NA3$PROX_CBD))
hdbresale_latlononly_CBD_NA4
```

The following code chunk filter the rows with valid distance value and write a copy of the csv in the file path

```{r eval=FALSE}
hdbresale_latlononly_CBD_NONA5 <- hdbresale_latlononly_CBD_NA3 %>%
                                  drop_na(PROX_CBD)
hdbresale_latlononly_CBD_NONA5

write.csv(hdbresale_latlononly_CBD_NONA5, "data/newaspatial/hdbresale_proxcbd5.csv", row.names = FALSE)
```

The following code chunk rbind all the dataset after getting the PROX_CBD of every row.

Data to bind includes:

- hdbresale_latlononly_CBD_NONA1, hdbresale_latlononly_CBD_NONA2, hdbresale_latlononly_CBD_NONA3, hdbresale_latlononly_CBD_NONA4 and hdbresale_latlononly_CBD_NONA5

```{r eval=FALSE}
hdbresale_PROXCBD <- rbind(hdbresale_latlononly_CBD_NONA1, hdbresale_latlononly_CBD_NONA2, hdbresale_latlononly_CBD_NONA3, hdbresale_latlononly_CBD_NONA4, hdbresale_latlononly_CBD_NONA5)

hdbresale_PROXCBD

write.csv(hdbresale_PROXCBD, "data/newaspatial/hdbresale_proxcbdfinal.csv", row.names = FALSE)
```

```{r eval=FALSE}
hdbresale_cbd <- read_csv("data/newaspatial/hdbresale_proxcbdfinal.csv")
```

```{r eval=FALSE}
hdbresale_cbd
sum(is.na(hdbresale_cbd$PROX_CBD))
```

```{r eval=FALSE}
hdbresale_latlongtogeowithcbdprox <- st_as_sf(hdbresale_cbd,
                                      coords = c("LONGITUDE", 
                                                 "LATITUDE"),
                                      crs=4326) %>%
                                      st_transform(crs = 3414)
```

The following code chunk plots the points to check if the imported data is plotted correctly. 

```{r eval=FALSE}
tmap_mode("view")
tm_shape(hdbresale_latlongtogeowithcbdprox)+
  tm_dots()
tmap_mode("plot")
```

### 4.3 Proximity to Eldercare

Import Eldercare data

The following code chunk import eldercare shapefile data using st_read.

```{r eval=FALSE}
eldercare_sf <- st_read(dsn = "data/independentvar/extracted", layer="ELDERCARE")
```

Calculate distances

The following code chunk:

- get the geometry from hdb and elderlycare sf
- retrieve coordinates in matrix form using st_coordinates function of sf package
- calculate the Great Circle distances (longlat set to TRUE) between hdb and elderlycare

```{r eval=FALSE}
hdb_df <- hdbresale_latlongtogeowithcbdprox$geometry
hdb <- st_coordinates(hdb_df)


elderlycare_df <- eldercare_sf$geometry
elderlycare <- st_coordinates(elderlycare_df)

dist_hdb_elderlycare <- spDists(hdb, elderlycare, longlat=TRUE)
```

```{r eval=FALSE}
write.csv(dist_hdb_elderlycare, "data/newaspatial/hdbtoeldercare.csv", row.names = FALSE)
```

Get min distances

The following code chunk:

- converts dist_hdb_elderlycare into df
- get the nearest Elderlycare distance for each hdb row using rowwise function of dplyr to check through a row and create a Min column using mutate function of dplyr package
- create PROX_EDLDERCARE and filter all the min value converted into km.

```{r eval=FALSE}

dist_hdb_elderlycare_df <- data.frame(dist_hdb_elderlycare)

dist_hdb_elderlycare_min <- dist_hdb_elderlycare_df %>% rowwise() %>% mutate(Min = min(c_across(X1:X133)))

PROX_ELDERLYCARE <- dist_hdb_elderlycare_min$Min/1000
```

Combine data

The following code chunk combines PROX_ELDERLYCARE with the most updated data, hdbresales_cdb, via cbind function of base package.

```{r eval=FALSE}
hdb_updated <- cbind(hdbresale_cbd, PROX_ELDERLYCARE)
```

```{r eval=FALSE}
write.csv(hdb_updated, "data/newaspatial/hdbupdated1.csv", row.names = FALSE)
```

### 4.4 Proximity to Hawker Centre

```{r eval=FALSE}
hawkercentre_sf <- st_read("data/independentvar/extracted/hawker-centres-geojson.geojson") %>%
                    st_transform(crs = 3414)
```

```{r eval=FALSE}
tmap_mode("view")
tm_shape(hawkercentre_sf)+
  tm_dots()
tmap_mode("plot")
```

```{r eval=FALSE}
hdb_updated_geometry <- st_as_sf(hdb_updated,
                          coords = c("LONGITUDE", 
                                     "LATITUDE"),
                          crs=4326) %>%
                          st_transform(crs = 3414)

hdb_df <- hdb_updated_geometry$geometry
hdb <- st_coordinates(hdb_df)

hawkercentre_df <- hawkercentre_sf$geometry
hawkercentre <- st_coordinates(hawkercentre_df)
hawkercentre <- hawkercentre[,c(1,2)]

dist_hdb_hawkercentre <- spDists(hdb, hawkercentre, longlat=TRUE)
```

```{r eval=FALSE}
write.csv(dist_hdb_hawkercentre, "data/newaspatial/hdbtohawker.csv", row.names = FALSE)
```

```{r eval=FALSE}

dist_hdb_hawkercentre_df <- data.frame(dist_hdb_hawkercentre)

dist_hdb_hawkercentre_min <- dist_hdb_hawkercentre_df %>% rowwise() %>% mutate(Min = min(c_across(X1:X125)))

PROX_HAWKER <- dist_hdb_hawkercentre_min$Min/1000
```

Combine data

The following code chunk combines PROX_HAWKER with the most updated data, hdb_updated, via cbind function of base package.

```{r eval=FALSE}
hdb_updated <- cbind(hdb_updated, PROX_HAWKER)
```

```{r eval=FALSE}
write.csv(hdb_updated, "data/newaspatial/hdbupdated2.csv", row.names = FALSE)
```

### 4.5 Proximity to MRT

```{r eval=FALSE}
mrtlrt_sf <- st_read(dsn = "data/independentvar/extracted", layer="MRTLRTStnPtt")
```

```{r eval=FALSE}
hdb_updated_geometry <- st_as_sf(hdb_updated,
                          coords = c("LONGITUDE", 
                                     "LATITUDE"),
                          crs=4326) %>%
                          st_transform(crs = 3414)

hdb_df <- hdb_updated_geometry$geometry
hdb <- st_coordinates(hdb_df)

mrtlrt_df <- mrtlrt_sf$geometry
mrtlrt <- st_coordinates(mrtlrt_df)

dist_hdb_mrtlrt <- spDists(hdb, mrtlrt, longlat=TRUE)
```

```{r eval=FALSE}
write.csv(dist_hdb_mrtlrt, "data/newaspatial/hdbtomrtlrt.csv", row.names = FALSE)
```

```{r eval=FALSE}

dist_hdb_mrtlrt_df <- data.frame(dist_hdb_mrtlrt)

dist_hdb_mrtlrt_min <- dist_hdb_mrtlrt_df %>% rowwise() %>% mutate(Min = min(c_across(X1:X185)))

PROX_MRTLRT <- dist_hdb_mrtlrt_min$Min/1000
```

Combine data

The following code chunk combines PROX_MRTLRT with the most updated data, hdb_updated, via cbind function of base package.

```{r eval=FALSE}
hdb_updated <- cbind(hdb_updated, PROX_MRTLRT)
```

```{r eval=FALSE}
write.csv(hdb_updated, "data/newaspatial/hdbupdated3.csv", row.names = FALSE)
```

```{r eval=FALSE}
hdb_updated <- read_csv("data/newaspatial/hdbupdated3.csv")
```


### 4.6 Proximity to Parks

```{r eval=FALSE}
parks_sf <- st_read("data/independentvar/extracted/parks-geojson.geojson") %>%
                    st_transform(crs = 3414)
```

```{r eval=FALSE}
hdb_updated_geometry <- st_as_sf(hdb_updated,
                          coords = c("LONGITUDE", 
                                     "LATITUDE"),
                          crs=4326) %>%
                          st_transform(crs = 3414)

hdb_df <- hdb_updated_geometry$geometry
hdb <- st_coordinates(hdb_df)

parks_df <- parks_sf$geometry
parks <- st_coordinates(parks_df)
parks <- parks[,c(1,2)]

dist_hdb_parks <- spDists(hdb, parks, longlat=TRUE)
```

```{r eval=FALSE}
write.csv(dist_hdb_parks, "data/newaspatial/hdbtoparks.csv", row.names = FALSE)
```

```{r eval=FALSE}
dist_hdb_parks_df <- data.frame(dist_hdb_parks)

dist_hdb_parks_min <- dist_hdb_parks_df %>% rowwise() %>% mutate(Min = min(c_across(X1:X350)))

PROX_PARKS <- dist_hdb_parks_min$Min/1000
```

Combine data

The following code chunk combines PROX_MRTLRT with the most updated data, hdb_updated, via cbind function of base package.

```{r eval=FALSE}
hdb_updated <- cbind(hdb_updated, PROX_PARKS)
```

```{r eval=FALSE}
write.csv(hdb_updated, "data/newaspatial/hdbupdated4.csv", row.names = FALSE)
```

### 4.7 Proximity to Supermarket

```{r eval=FALSE}
supermarkets_sf <- st_read("data/independentvar/extracted/supermarkets-geojson.geojson") %>%
                    st_transform(crs = 3414)
```

```{r eval=FALSE}
hdb_updated_geometry <- st_as_sf(hdb_updated,
                          coords = c("LONGITUDE", 
                                     "LATITUDE"),
                          crs=4326) %>%
                          st_transform(crs = 3414)

hdb_df <- hdb_updated_geometry$geometry
hdb <- st_coordinates(hdb_df)

supermarkets_df <- supermarkets_sf$geometry
supermarkets <- st_coordinates(supermarkets_df)
supermarkets <- supermarkets[,c(1,2)]

dist_hdb_supermarkets <- spDists(hdb, supermarkets, longlat=TRUE)
```

```{r eval=FALSE}
write.csv(dist_hdb_supermarkets, "data/newaspatial/hdbtosupermarkets.csv", row.names = FALSE)
```

```{r eval=FALSE}
dist_hdb_supermarkets_df <- data.frame(dist_hdb_supermarkets)

dist_hdb_supermarkets_min <- dist_hdb_supermarkets_df %>% rowwise() %>% mutate(Min = min(c_across(X1:X526)))

PROX_SUPERMARKETS <- dist_hdb_supermarkets_min$Min/1000
```

Combine data

The following code chunk combines PROX_MRTLRT with the most updated data, hdb_updated, via cbind function of base package.

```{r eval=FALSE}
hdb_updated <- cbind(hdb_updated, PROX_SUPERMARKETS)
```

```{r eval=FALSE}
write.csv(hdb_updated, "data/newaspatial/hdbupdated5.csv", row.names = FALSE)
```


### 4.8 Proximity to CHAS clinics

```{r eval=FALSE}
clinics_sf <- st_read("data/independentvar/extracted/chas-clinics-geojson.geojson") %>%
                    st_transform(crs = 3414)
```

```{r eval=FALSE}
hdb_updated_geometry <- st_as_sf(hdb_updated,
                          coords = c("LONGITUDE", 
                                     "LATITUDE"),
                          crs=4326) %>%
                          st_transform(crs = 3414)

hdb_df <- hdb_updated_geometry$geometry
hdb <- st_coordinates(hdb_df)

clinics_df <- clinics_sf$geometry
clinics <- st_coordinates(clinics_df)
clinics <- clinics[,c(1,2)]

dist_hdb_clinics <- spDists(hdb, clinics, longlat=TRUE)
```

```{r eval=FALSE}
write.csv(dist_hdb_clinics, "data/newaspatial/hdbtoclinics.csv", row.names = FALSE)
```

```{r eval=FALSE}
dist_hdb_clinics_df <- data.frame(dist_hdb_clinics)

dist_hdb_clinics_min <- dist_hdb_clinics_df %>% rowwise() %>% mutate(Min = min(c_across(X1:X1167)))

PROX_CLINICS <- dist_hdb_clinics_min$Min/1000
```

Combine data

The following code chunk combines PROX_MRTLRT with the most updated data, hdb_updated, via cbind function of base package.

```{r eval=FALSE}
hdb_updated <- cbind(hdb_updated, PROX_CLINICS)
```

```{r eval=FALSE}
write.csv(hdb_updated, "data/newaspatial/hdbupdated6.csv", row.names = FALSE)
```

```{r eval=FALSE}
hdb_updated <- read_csv("data/newaspatial/hdbupdated6.csv")
```


### 4.9 Proximity to Kindergartens and Number of Kindergartens within 350m

```{r eval=FALSE}
kindergartens_sf <- st_read("data/independentvar/extracted/kindergartens-geojson.geojson") %>%
                    st_transform(crs = 3414)
```

```{r eval=FALSE}
hdb_updated_geometry <- st_as_sf(hdb_updated,
                          coords = c("LONGITUDE", 
                                     "LATITUDE"),
                          crs=4326) %>%
                          st_transform(crs = 3414)

hdb_df <- hdb_updated_geometry$geometry
hdb <- st_coordinates(hdb_df)

kindergartens_df <- kindergartens_sf$geometry
kindergartens <- st_coordinates(kindergartens_df)
kindergartens <- kindergartens[,c(1,2)]

dist_hdb_kindergartens <- spDists(hdb, kindergartens, longlat=TRUE)
```

```{r eval=FALSE}
write.csv(dist_hdb_kindergartens, "data/newaspatial/hdbtokindergartens.csv", row.names = FALSE)
```

```{r eval=FALSE}
dist_hdb_kindergartens_df <- data.frame(dist_hdb_kindergartens)

dist_hdb_kindergartens_min <- dist_hdb_kindergartens_df %>% rowwise() %>% mutate(Min = min(c_across(X1:X448)))

PROX_KINDERGARTENS <- dist_hdb_kindergartens_min$Min/1000
```

```{r eval=FALSE}
dist_hdb_kindergartens_df$num_within_350m <- rowSums(dist_hdb_kindergartens_df <= 350)

NUM_KINDERGARDEN_350M <- dist_hdb_kindergartens_df$num_within_350m
```

Combine data

The following code chunk combines PROX_MRTLRT with the most updated data, hdb_updated, via cbind function of base package.

```{r eval=FALSE}
hdb_updated <- cbind(hdb_updated, PROX_KINDERGARTENS, NUM_KINDERGARDEN_350M)
```

```{r eval=FALSE}
write.csv(hdb_updated, "data/newaspatial/hdbupdated7.csv", row.names = FALSE)
```


### 4.10  Proximity to childcare centres and Numbers of childcare centres within 350m

```{r eval=FALSE}
childcare_sf <- st_read("data/independentvar/extracted/child-care-services-geojson.geojson") %>%
                    st_transform(crs = 3414)
```

```{r eval=FALSE}
hdb_updated_geometry <- st_as_sf(hdb_updated,
                          coords = c("LONGITUDE", 
                                     "LATITUDE"),
                          crs=4326) %>%
                          st_transform(crs = 3414)

hdb_df <- hdb_updated_geometry$geometry
hdb <- st_coordinates(hdb_df)

childcare_df <- childcare_sf$geometry
childcare <- st_coordinates(childcare_df)
childcare <- childcare[,c(1,2)]

dist_hdb_childcare <- spDists(hdb, childcare, longlat=TRUE)
```

```{r eval=FALSE}
write.csv(dist_hdb_childcare, "data/newaspatial/hdbtochilcare.csv", row.names = FALSE)
```

```{r eval=FALSE}
dist_hdb_childcare_df <- data.frame(dist_hdb_childcare)

dist_hdb_childcare_min <- dist_hdb_childcare_df %>% rowwise() %>% mutate(Min = min(c_across(X1:X1545)))

PROX_CHILDCARE <- dist_hdb_childcare_min$Min/1000
```

```{r eval=FALSE}
dist_hdb_childcare_df$num_within_350m <- rowSums(dist_hdb_childcare_df <= 350)

NUM_CHILDCARE_350M <- dist_hdb_childcare_df$num_within_350m
```

Combine data

The following code chunk combines PROX_MRTLRT with the most updated data, hdb_updated, via cbind function of base package.

```{r eval=FALSE}
hdb_updated <- cbind(hdb_updated, PROX_CHILDCARE, NUM_CHILDCARE_350M)
```

```{r eval=FALSE}
write.csv(hdb_updated, "data/newaspatial/hdbupdated8.csv", row.names = FALSE)
```

### 4.11 Proximity to bus stop and Numbers of bus stop within 350m

```{r eval=FALSE}
busstop_sf <- st_read(dsn = "data/independentvar/extracted", layer="BusStop")
```

```{r eval=FALSE}
hdb_updated_geometry <- st_as_sf(hdb_updated,
                          coords = c("LONGITUDE", 
                                     "LATITUDE"),
                          crs=4326) %>%
                          st_transform(crs = 3414)

hdb_df <- hdb_updated_geometry$geometry
hdb <- st_coordinates(hdb_df)

busstop_df <- busstop_sf$geometry
busstop <- st_coordinates(busstop_df)
busstop <- busstop[,c(1,2)]

dist_hdb_busstop <- spDists(hdb, busstop, longlat=TRUE)
```

```{r eval=FALSE}
write.csv(dist_hdb_busstop, "data/newaspatial/hdbtobusstop.csv", row.names = FALSE)
```

```{r eval=FALSE}
dist_hdb_busstop_df <- data.frame(dist_hdb_busstop)

dist_hdb_busstop_min <- dist_hdb_busstop_df %>% rowwise() %>% mutate(Min = min(c_across(X1:X5156)))

PROX_BUSSTOP <- dist_hdb_busstop_min$Min/1000
```

```{r eval=FALSE}
write.csv(dist_hdb_busstop_min, "data/newaspatial/hdbtobusstop_min.csv", row.names = FALSE)
```

```{r eval=FALSE}
dist_hdb_busstop_df$num_within_350m <- rowSums(dist_hdb_busstop_df <= 350)
```

```{r eval=FALSE}
NUM_BUSSTOP_350M <- dist_hdb_busstop_df$num_within_350m
```

Combine data

The following code chunk combines PROX_MRTLRT with the most updated data, hdb_updated, via cbind function of base package.

```{r eval=FALSE}
hdb_updated <- cbind(hdb_updated, PROX_BUSSTOP, NUM_BUSSTOP_350M)
```

```{r eval=FALSE}
write.csv(hdb_updated, "data/newaspatial/hdbupdated9.csv", row.names = FALSE)
```

```{r eval=FALSE}
hdb_updated <- read_csv("data/newaspatial/hdbupdated9.csv")
```

### 4.12 Numbers of primary school within 1km

```{r eval=FALSE}
schools_df <- read_csv("data/independentvar/extracted/Singapore+Schools-2021-10-21.csv")
```

Filter Primary school

```{r eval=FALSE}
primary_schools_df <- schools_df %>% filter(grepl('PRIMARY SCHOOL', Name))
```

Get Address for Primary School

```{r eval=FALSE}
for (i in 1:nrow(primary_schools_df)) {
  postalcode <- primary_schools_df[i,'Zip/Postal Code']
  
  url = paste('https://developers.onemap.sg/commonapi/search?searchVal=', postalcode, '&returnGeom=Y&getAddrDetails=Y&pageNum=1')
  encoded_url <- URLencode(url)
  
  getcoordinate <- GET(encoded_url)
  
  jsonParsed <- content(getcoordinate,as="parsed")
  
  if (length(jsonParsed$results) > 0) {
    primary_schools_df[i,'LATITUDE'] = jsonParsed$results[[1]]$LATITUDE
    primary_schools_df[i,'LONGITUDE'] = jsonParsed$results[[1]]$LONGITUDE
  }
}
```

```{r eval=FALSE}
primary_schools_df[100,'LATITUDE'] = '1.3038033016307733'
primary_schools_df[100,'LONGITUDE'] = '103.84619018095628'
```


```{r eval=FALSE}
primary_schools_df_selected <- primary_schools_df %>% select('Name', 'Address', 'Zip/Postal Code', 'LATITUDE', 'LONGITUDE')
```

```{r eval=FALSE}
write.csv(primary_schools_df_selected, "data/newaspatial/primaryschoollatlong.csv", row.names = FALSE)
```

```{r eval=FALSE}
primary_schools_sf <- st_as_sf(primary_schools_df_selected,
                    coords = c("LONGITUDE", 
                               "LATITUDE"),
                    crs=4326) %>%
  st_transform(crs = 3414)
```


```{r eval=FALSE}
hdb_updated_geometry <- st_as_sf(hdb_updated,
                          coords = c("LONGITUDE", 
                                     "LATITUDE"),
                          crs=4326) %>%
                          st_transform(crs = 3414)

hdb_df <- hdb_updated_geometry$geometry
hdb <- st_coordinates(hdb_df)

prisch_df <- primary_schools_sf$geometry
prisch <- st_coordinates(prisch_df)
prisch <- prisch[,c(1,2)]

dist_hdb_prisch <- spDists(hdb, prisch, longlat=TRUE)
```

```{r eval=FALSE}
write.csv(dist_hdb_prisch, "data/newaspatial/hdbtoprisch.csv", row.names = FALSE)
```

```{r eval=FALSE}
dist_hdb_prisch_df <- data.frame(dist_hdb_prisch)

dist_hdb_prisch_min <- dist_hdb_prisch_df %>% rowwise() %>% mutate(Min = min(c_across(X1:X156)))

PROX_PRISCH <- dist_hdb_prisch_min$Min/1000
```

```{r eval=FALSE}
dist_hdb_prisch_df$num_within_1km <- rowSums(dist_hdb_prisch_df <= 1000)

NUM_PRISCH_1KM <- dist_hdb_prisch_df$num_within_1km
```

Combine data

The following code chunk combines PROX_MRTLRT with the most updated data, hdb_updated, via cbind function of base package.

```{r eval=FALSE}
hdb_updated <- cbind(hdb_updated, PROX_PRISCH, NUM_PRISCH_1KM)
```

```{r eval=FALSE}
write.csv(hdb_updated, "data/newaspatial/hdbupdated10.csv", row.names = FALSE)
```

### 4.13 hdb final

The following code chunk creates dummy variable for storey_range column using dummy function of dummies package.

```{r eval=FALSE}
hdb_updated1 <- cbind(hdb_updated, dummy(hdb_updated$storey_range, sep = "_")) 
```

The following code chunk replace the dummy's column name from "hdb_updated_01 TO 03" format to "01TO03" format using gsub function of base package.

```{r eval=FALSE}
names(hdb_updated1) = gsub("hdb_updated_", "", names(hdb_updated1))/
names(hdb_updated1) = gsub(" ", "", names(hdb_updated1))
```

```{r eval=FALSE}
write.csv(hdb_updated1, "data/newaspatial/hdbupdated11.csv", row.names = FALSE)
```

The following code chunk then select all the require column in hdb_final using select function

```{r eval=FALSE}
hdb_final <- hdb_updated1 %>%
            select(address, storey_range, LATITUDE, LONGITUDE, resale_price, floor_area_sqm, remaining_lease_year, PROX_CBD, PROX_ELDERLYCARE, PROX_HAWKER, PROX_MRTLRT, PROX_PARKS, PROX_SUPERMARKETS, PROX_CLINICS, NUM_KINDERGARDEN_350M, NUM_CHILDCARE_350M, NUM_BUSSTOP_350M, NUM_PRISCH_1KM, `01TO03`, `04TO06`, `07TO09`, `10TO12`, `13TO15`, `16TO18`, `19TO21`, `22TO24`, `25TO27`, `28TO30`, `31TO33`, `34TO36`, `37TO39`, `40TO42`, `43TO45`, `46TO48`, `49TO51`)
```

The following code chunk save hdb_final as csv using write.csv function

```{r eval=FALSE}
write.csv(hdb_final, "data/aspatial/hdb_final1.csv", row.names = FALSE)
```

## 5. Data Import

### 5.1 Geospatial Data

The following code chunk import MP14_SUBZONE_WEB_PL using st_read function of sf package.

```{r}
mpsz = st_read(dsn = "data/geospatial", layer = "MP14_SUBZONE_WEB_PL")
```

The following code chunk update the EPSG code 3414 using st_transform of sf package and retrieve coordinate using st_crs of sf package

```{r}
mpsz_svy21 <- st_transform(mpsz, 3414)
st_crs(mpsz_svy21)
```

We can see that the EPSG is 3414 which is correct.

### 5.2 Aspatial data

hdb_final

The following code chunk read hdb_final csv file as tibble data frame using read_csv function and glimpse to display the data 

```{r}
hdb_final <- read_csv("data/aspatial/hdb_final.csv")
glimpse(hdb_final)
```

We can see that there are 15901 rows of data with 35 columns. The coordinate is in LATITUDE and LONGITUDE format.

```{r}
hdb_final <- hdb_final %>% 
                rename(
                  storey01TO03 = `01TO03`,
                  storey04TO06 = `04TO06`,
                  storey07TO09 = `07TO09`,
                  storey10TO12 = `10TO12`,
                  storey13TO15 = `13TO15`,
                  storey16TO18 = `16TO18`,
                  storey19TO21 = `19TO21`,
                  storey22TO24 = `22TO24`,
                  storey25TO27 = `25TO27`,
                  storey28TO30 = `28TO30`,
                  storey31TO33 = `31TO33`,
                  storey34TO36 = `34TO36`,
                  storey37TO39 = `37TO39`,
                  storey40TO42 = `40TO42`,
                  storey43TO45 = `43TO45`,
                  storey46TO48 = `46TO48`,
                  storey49TO51 = `49TO51`
                  )
```

### 5.3 Convert aspatial df to sf

The following code chunk converts hdb_final dataframe into sf dataframe using st_as_sf function of sf package. The coordinate is then converted into svy21 EPSG:3414 FROM WGS84 usign st_transform function.

```{r}
hdb_final_sf <- st_as_sf(hdb_final,
                            coords = c("LONGITUDE", "LATITUDE"),
                            crs=4326) %>%
                  st_transform(crs=3414)
head(hdb_final_sf)
```

## 6. EDA

### 6.1 Statistical Graph

Resale Price

The following code chunk plots the distribution of resale_price using ggplot function of ggplot2 package.

```{r}
ggplot(data=hdb_final_sf, aes(x= `resale_price`)) +
  geom_histogram(bins=20, color="black", fill="light blue")
```

From the above, we can see a normal distribution. Majority of the four room hdb were transacted for about $300000 to 400000.

Other variables

Next, we are interested to see the distribution of other variables.

The following code chunk plots the distribution of other variables using ggplot function of ggplot2 package and arrange them in columns of 3 using ggarrange function of ggpubr package.

```{r}
floor_area_sqm <- ggplot(data=hdb_final_sf, aes(x= `floor_area_sqm`)) +
  geom_histogram(bins=20, color="black", fill="light blue")

remaining_lease_year <- ggplot(data=hdb_final_sf, aes(x= `remaining_lease_year`)) +
  geom_histogram(bins=20, color="black", fill="light blue")

PROX_CBD <- ggplot(data=hdb_final_sf, aes(x= `PROX_CBD`)) +
  geom_histogram(bins=20, color="black", fill="light blue")

PROX_ELDERLYCARE <- ggplot(data=hdb_final_sf, aes(x= `PROX_ELDERLYCARE`)) +
  geom_histogram(bins=20, color="black", fill="light blue")

PROX_HAWKER <- ggplot(data=hdb_final_sf, aes(x= `PROX_HAWKER`)) +
  geom_histogram(bins=20, color="black", fill="light blue")

PROX_MRTLRT <- ggplot(data=hdb_final_sf, aes(x= `PROX_MRTLRT`)) +
  geom_histogram(bins=20, color="black", fill="light blue")

PROX_PARKS <- ggplot(data=hdb_final_sf, aes(x= `PROX_PARKS`)) +
  geom_histogram(bins=20, color="black", fill="light blue")

PROX_SUPERMARKETS <- ggplot(data=hdb_final_sf, aes(x= `PROX_SUPERMARKETS`)) +
  geom_histogram(bins=20, color="black", fill="light blue")

PROX_CLINICS <- ggplot(data=hdb_final_sf, aes(x= `PROX_CLINICS`)) +
  geom_histogram(bins=20, color="black", fill="light blue")

ggarrange(floor_area_sqm, remaining_lease_year, PROX_CBD, PROX_ELDERLYCARE, PROX_HAWKER, PROX_MRTLRT, PROX_PARKS, PROX_SUPERMARKETS, PROX_CLINICS, ncol = 3, nrow = 3)

```

From the above, we can see that most of the variables are normally distributed except remaining_lease_year. Majority of the transacted four-room hdb has remaining_lease_year of above 90 years.

### 6.2 Statiscal Point Map

Resale Price

The following code chunk plots the resale price on an interactive mode with OpenStreetMap basemap using function of tmap package.

```{r}
tmap_mode("view")
tm_shape(hdb_final_sf) +  
  tm_dots(col = "resale_price",
          alpha = 0.6,
          style="quantile") +
  tm_view(set.zoom.limits = c(11,14)) +
tm_basemap("OpenStreetMap")
tmap_mode("plot")
```

From the interactive map, we can see that hdb in central and south area tends to have higher resale price (darker red points).

## 7. Hedonic Pricing Model

### 7.1 Multiple Linear Regression Model

#### 7.1.1 Relationship between Independent variables

```{r fig.width=8, fig.height=8}
corrplot(cor(hdb_final[, 6:35]), diag = FALSE, order = "AOE",
         tl.pos = "td", tl.cex = 0.7, number.cex=0.5, method = "number", type = "upper")
```

From the scatterplot above, we can see that NUM_BUSSTOP_350M is highly correlated to NUM_CHILDCARE_350M and NUM_KINDERGARDEN_350M with correlation coefficient of 0.93 and 0.84 respective. NUM_CHILDCARE_350M and NUM_KINDERGARDEN_350M are also highly correlated with correlation coefficient of 0.84. Hence, we should only include one out of three of them in the subsequent model building. Hence, NUM_BUSSTOP_350M and NUM_KINDERGARDEN_350M will be excluded.

#### 7.1.2 Hedonic pricing model using multiple linear regression method

The following code chunk builds a multiple linear regression model using lm function of stats package.

Note that `49TO51` dummy variable is excluded since because we should only have n-1 dummy variable. It will have a strong correlation with other independent variable if we were to include it.

```{r}
hdb_final_mlr <- lm(formula = resale_price ~ floor_area_sqm + remaining_lease_year + PROX_CBD + PROX_ELDERLYCARE + PROX_HAWKER + PROX_MRTLRT + PROX_PARKS + PROX_SUPERMARKETS + PROX_CLINICS + NUM_CHILDCARE_350M + NUM_PRISCH_1KM + storey01TO03 + storey04TO06 + storey07TO09 + storey10TO12 + storey13TO15 + storey16TO18 + storey19TO21 + storey22TO24 + storey25TO27 + storey28TO30 + storey31TO33 + storey34TO36 + storey37TO39 + storey40TO42 + storey43TO45 + storey46TO48, data=hdb_final_sf)

summary(hdb_final_mlr)
```

From the above, we can see that there are some independent variables that are statistically not significant. Variables such as PROX_MRTLRT, PROX_SUPERMARKETS, PROX_CLINICS, NUM_PRISCH_1KM, storey43TO45 and storey46TO48 have p-value above 0.05 and are not statistically significant. We will exclude these variable when we calibrate the revised model.

The code chunk calibrate the revised model using lm function with variables that are not statistically significant removed. Ordinary least squares regression is then done by running ols_regress function of olsrr package.

```{r}
hdb_final_mlr1 <- lm(formula = resale_price ~ floor_area_sqm + remaining_lease_year + PROX_CBD + PROX_ELDERLYCARE + PROX_HAWKER + PROX_PARKS + NUM_CHILDCARE_350M + storey01TO03 + storey04TO06 + storey07TO09 + storey10TO12 + storey13TO15 + storey16TO18 + storey19TO21 + storey22TO24 + storey25TO27 + storey28TO30 + storey31TO33 + storey34TO36 + storey37TO39 + storey40TO42, data=hdb_final_sf)

ols_regress(hdb_final_mlr1)
```

#### 7.1.3 Checks for multicolinearity

The following code chunk test for sign of multicolinearity using ols_vif_tol function of olsrr package.

```{r}
summary(hdb_final_mlr1)
```

```{r eval=FALSE}
ols_vif_tol(hdb_final_mlr1)
```

There are some independent variables with VIF value above 10 which means that there are sign of multicollinearity. Hence we would want to calibrate the model again by removing independent variables with VIF above 10.

```{r}
hdb_final_mlr2 <- lm(formula = resale_price ~ floor_area_sqm + remaining_lease_year + PROX_CBD + PROX_ELDERLYCARE + PROX_HAWKER + PROX_PARKS + NUM_CHILDCARE_350M + storey31TO33 + storey34TO36 + storey37TO39 + storey40TO42, data=hdb_final_sf)
```

```{r}
ols_regress(hdb_final_mlr2)
```

#### 7.1.4 Test for Non-Linearity

```{r}
ols_plot_resid_fit(hdb_final_mlr2)
```

#### 7.1.5 Test for Normality Assumption

```{r}
ols_plot_resid_hist(hdb_final_mlr2)
```


#### 7.1.6 Testing for Spatial Autocorrelation

```{r}
mlr.output <- as.data.frame(hdb_final_mlr2$residuals)
```

```{r}
hdb_final_res_sf <- cbind(hdb_final_sf, hdb_final_mlr2$residuals) %>%
                        rename(`MLR_RES` = `hdb_final_mlr2.residuals`)
```

```{r}
hdb_final_sp <- as_Spatial(hdb_final_res_sf)
hdb_final_sp
```

```{r}
tmap_mode("view")
tm_shape(hdb_final_res_sf) +  
  tm_dots(col = "MLR_RES",
          alpha = 0.6,
          style="quantile") +
  tm_view(set.zoom.limits = c(11,14)) +
tm_basemap("OpenStreetMap")
tmap_mode("plot")
```

```{r}
nb <- dnearneigh(coordinates(hdb_final_sp), 0, 1500, longlat = FALSE)
summary(nb)
```

```{r}
nb_lw <- nb2listw(nb, style = 'W')
summary(nb_lw)
```

```{r}
lm.morantest(hdb_final_mlr2, nb_lw)
```

## 8. Building Hedonic Pricing Models using GWmodel

### 8.1 Fixed Bandwidth GWR model

#### 8.1.1 Computing fixed bandwidth

longlat set to TRUE since the data preparation also use great circle distances.

```{r eval=FALSE}
bw.fixed <- bw.gwr(formula = resale_price ~ floor_area_sqm + remaining_lease_year + PROX_CBD + PROX_ELDERLYCARE + PROX_HAWKER +
PROX_PARKS + NUM_CHILDCARE_350M + storey31TO33 + storey34TO36 + storey37TO39 + storey40TO42, data=hdb_final_sp, approach="CV", kernel="gaussian", adaptive=FALSE, longlat=TRUE)
```

#### 8.1.2 GWModel method - fixed bandwith

```{r eval=FALSE}
gwr.fixed <- gwr.basic(formula = resale_price ~ floor_area_sqm + remaining_lease_year + PROX_CBD + PROX_ELDERLYCARE + PROX_HAWKER +
PROX_PARKS + NUM_CHILDCARE_350M + storey31TO33 + storey34TO36 + storey37TO39 + storey40TO42, data=hdb_final_sp, bw=bw.fixed, kernel="gaussian", adaptive=FALSE, longlat=TRUE)
```

```{r}
gwr.fixed
```


### 8.2 Adaptive Bandwidth GWR model

#### 8.2.1 Computing adaptive bandwidth

Notice that the dummy variables name have an addition "X" at the front in hdb_final_sp

```{r eval=FALSE}
bw.adaptive <- bw.gwr(formula = resale_price ~ floor_area_sqm + remaining_lease_year + PROX_CBD + PROX_ELDERLYCARE + PROX_HAWKER +
PROX_PARKS + NUM_CHILDCARE_350M + storey31TO33 + storey34TO36 + storey37TO39 + storey40TO42, data=hdb_final_sp, approach="CV", kernel="gaussian", adaptive=TRUE, longlat=TRUE)
```

#### 8.2.2 GWModel method - adaptive bandwith

```{r eval=FALSE}
gwr.adaptive <- gwr.basic(formula = resale_price ~ floor_area_sqm + remaining_lease_year + PROX_CBD + PROX_ELDERLYCARE + PROX_HAWKER +
PROX_PARKS + NUM_CHILDCARE_350M + storey31TO33 + storey34TO36 + storey37TO39 + storey40TO42, data=hdb_final_sp, bw=bw.adaptive, kernel="gaussian", adaptive=TRUE, longlat=TRUE)
```

```{r}
gwr.adaptive
```


## 9. Visualising GWR Output

### 9.1 Converting SDF into sf data.frame

```{r eval=FALSE}
hdb_final_sf.adaptive <- st_as_sf(gwr.adaptive$SDF) %>%
  st_transform(crs=3414)
```

```{r eval=FALSE}
hdb_final_sf.adaptive.svy21 <- st_transform(hdb_final_sf.adaptive, 3414)
hdb_final_sf.adaptive.svy21  
```

```{r eval=FALSE}
gwr.adaptive.output <- as.data.frame(gwr.adaptive$SDF)
hdb_final_sf.adaptive <- cbind(hdb_final_res_sf, as.matrix(gwr.adaptive.output))
```

```{r eval=FALSE}
glimpse(hdb_final_sf.adaptive)
```

```{r}
hdb_final_sf.fixed <- st_as_sf(gwr.fixed$SDF) %>%
  st_transform(crs=3414)
```

```{r}
hdb_final_sf.fixed.svy21 <- st_transform(hdb_final_sf.fixed, 3414)
hdb_final_sf.fixed.svy21  
```

```{r}
gwr.fixed.output <- as.data.frame(gwr.fixed$SDF)
hdb_final_sf.fixed <- cbind(hdb_final_res_sf, as.matrix(gwr.fixed.output))
```

```{r}
glimpse(hdb_final_sf.fixed)
```


### 9.2 Visualing LOCAL R2

```{r}
tmap_mode("view")
tm_shape(mpsz_svy21)+
  tm_polygons(alpha = 0.1) +
  tmap_options(check.and.fix = TRUE) +
tm_shape(hdb_final_sf.fixed) +  
  tm_dots(col = "Local_R2",
          border.col = "gray60",
          border.lwd = 1) +
  tm_view(set.zoom.limits = c(11,14))
tmap_mode("plot")
```

```{r eval=FALSE}
STOREY01TO03 <- ggplot(data=hdb_final.sf, aes(x= `01TO03`)) +
  geom_histogram(bins=20, color="black", fill="light blue")

STOREY04TO06 <- ggplot(data=hdb_final.sf, aes(x= `04TO06`)) +
  geom_histogram(bins=20, color="black", fill="light blue")

STOREY07TO09 <- ggplot(data=hdb_final.sf, aes(x= `07TO09`)) +
  geom_histogram(bins=20, color="black", fill="light blue")

STOREY10TO12 <- ggplot(data=hdb_final.sf, aes(x= `10TO12`)) +
  geom_histogram(bins=20, color="black", fill="light blue")

STOREY13TO15 <- ggplot(data=hdb_final.sf, aes(x= `13TO15`)) +
  geom_histogram(bins=20, color="black", fill="light blue")

STOREY16TO18 <- ggplot(data=hdb_final.sf, aes(x= `16TO18`)) +
  geom_histogram(bins=20, color="black", fill="light blue")

STOREY19TO21 <- ggplot(data=hdb_final.sf, aes(x= `19TO21`)) +
  geom_histogram(bins=20, color="black", fill="light blue")

STOREY22TO24 <- ggplot(data=hdb_final.sf, aes(x= `22TO24`)) +
  geom_histogram(bins=20, color="black", fill="light blue")

STOREY25TO27 <- ggplot(data=hdb_final.sf, aes(x= `25TO27`)) +
  geom_histogram(bins=20, color="black", fill="light blue")

STOREY28TO30 <- ggplot(data=hdb_final.sf, aes(x= `28TO30`)) +
  geom_histogram(bins=20, color="black", fill="light blue")

STOREY31TO33 <- ggplot(data=hdb_final.sf, aes(x= `31TO33`)) +
  geom_histogram(bins=20, color="black", fill="light blue")

STOREY34TO36 <- ggplot(data=hdb_final.sf, aes(x= `34TO36`)) +
  geom_histogram(bins=20, color="black", fill="light blue")

STOREY37TO39 <- ggplot(data=hdb_final.sf, aes(x= `37TO39`)) +
  geom_histogram(bins=20, color="black", fill="light blue")

STOREY40TO42 <- ggplot(data=hdb_final.sf, aes(x= `40TO42`)) +
  geom_histogram(bins=20, color="black", fill="light blue")

STOREY43TO45 <- ggplot(data=hdb_final.sf, aes(x= `43TO45`)) +
  geom_histogram(bins=20, color="black", fill="light blue")

STOREY46TO48 <- ggplot(data=hdb_final.sf, aes(x= `46TO48`)) +
  geom_histogram(bins=20, color="black", fill="light blue")

STOREY49TO51 <- ggplot(data=hdb_final.sf, aes(x= `49TO51`)) +
  geom_histogram(bins=20, color="black", fill="light blue")

NUM_KINDERGARDEN_350M <- ggplot(data=hdb_final.sf, aes(x= `NUM_KINDERGARDEN_350M`)) +
  geom_histogram(bins=20, color="black", fill="light blue")

NUM_CHILDCARE_350M <- ggplot(data=hdb_final.sf, aes(x= `NUM_CHILDCARE_350M`)) +
  geom_histogram(bins=20, color="black", fill="light blue")

NUM_BUSSTOP_350M <- ggplot(data=hdb_final.sf, aes(x= `NUM_BUSSTOP_350M`)) +
  geom_histogram(bins=20, color="black", fill="light blue")

NUM_PRISCH_1KM <- ggplot(data=hdb_final.sf, aes(x= `NUM_PRISCH_1KM`)) +
  geom_histogram(bins=20, color="black", fill="light blue")

STOREY01TO03, STOREY04TO06, STOREY07TO09, STOREY10TO12, STOREY13TO15, STOREY16TO18, STOREY19TO21, STOREY22TO24, STOREY25TO27, STOREY28TO30, STOREY31TO33, STOREY34TO36, STOREY37TO39, STOREY40TO42, STOREY43TO45, STOREY46TO48, STOREY49TO51

NUM_KINDERGARDEN_350M, NUM_CHILDCARE_350M, NUM_BUSSTOP_350M, NUM_PRISCH_1KM
```
