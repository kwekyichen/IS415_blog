---
title: "Hands-on_Ex08"
description: |
  I have learned to to calibrate geographically weighted regression models using GWmodel package.
author:
  - name: Kwek Yi Chen
    url: https://example.com/kwekyichen
date: 10-17-2021
output:
  distill::distill_article:
    self_contained: false
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
```

## Install Packages

GWmodel for Geospatial statistical modelling 

sf for Spatial data handling

tidyverse, especially readr, ggplot2 and dplyr for Attribute data handling

tmap for Choropleth mapping

```{r}
packages = c('olsrr', 'corrplot', 'ggpubr', 'sf', 'spdep', 'GWmodel', 'tmap', 'tidyverse')
for (p in packages){
  if(!require(p, character.only = T)){
    install.packages(p)
  }
  library(p,character.only = T)
}
```

## Short note about GWmodel

GWmodel provides a collection of localised spatial statistical methods. They are GW summary statistics, GW principal components analysis, GW discriminant analysis and various forms of GW regression; some of which are provided in basic and robust (outlier resistant) forms. Outputs or parameters of the GWmodel are mapped to provide a useful exploratory tool, which can often precede (and direct) a more traditional or sophisticated statistical analysis.

## Geospatial Data Wrangling

### Importing geospatial data

```{r}
mpsz = st_read(dsn = "data/geospatial", layer = "MP14_SUBZONE_WEB_PL")
```

### CRS transformation

```{r}
mpsz_svy21 <- st_transform(mpsz, 3414)
```


```{r}
st_crs(mpsz_svy21)
```

extent of mpsz_svy21

```{r}
st_bbox(mpsz_svy21) ##view extent
```

## Aspatial Data Wrangling

### Importing the aspatial data

```{r}
condo_resale = read_csv("data/aspatial/Condo_resale_2015.csv")
```


```{r}
glimpse(condo_resale)
```

```{r}
summary(condo_resale)
```

### Convert Aspatial df into sf object

```{r}
condo_resale.sf <- st_as_sf(condo_resale,
                            coords = c("LONGITUDE", "LATITUDE"),
                            crs=4326) %>%
  st_transform(crs=3414)
head(condo_resale.sf)
```

## EDA

### EDA using statistical graphics

Plot distribution of SELLING_PRICE

```{r}
ggplot(data=condo_resale.sf, aes(x=`SELLING_PRICE`)) +
  geom_histogram(bins=20, color="black", fill="light blue")
```

Analysis: Rightly skewed.

Normalisation log transformation

```{r}
condo_resale.sf <- condo_resale.sf %>%
  mutate(`LOG_SELLING_PRICE` = log(SELLING_PRICE))
```

Plot the log transformed SELLING_PRICE

```{r}
ggplot(data=condo_resale.sf, aes(x=`LOG_SELLING_PRICE`)) +
  geom_histogram(bins=20, color="black", fill="light blue")
```

## Multiple Histogram Plots distribution of variables

Multiple small histogram using ggarrange() of ggpubr package. ggarrnage() is used to organised these histogram into a 4 columns by 3 rows small multiple plot.

```{r}
AREA_SQM <- ggplot(data=condo_resale.sf, aes(x= `AREA_SQM`)) +
  geom_histogram(bins=20, color="black", fill="light blue")
AGE <- ggplot(data=condo_resale.sf, aes(x= `AGE`)) +
  geom_histogram(bins=20, color="black", fill="light blue")  
PROX_CBD <- ggplot(data=condo_resale.sf, aes(x= `PROX_CBD`)) +
  geom_histogram(bins=20, color="black", fill="light blue")
PROX_CHILDCARE <- ggplot(data=condo_resale.sf, aes(x= `PROX_CHILDCARE`)) +
  geom_histogram(bins=20, color="black", fill="light blue")
PROX_ELDERLYCARE <- ggplot(data=condo_resale.sf, aes(x= `PROX_ELDERLYCARE`)) +
  geom_histogram(bins=20, color="black", fill="light blue")
PROX_URA_GROWTH_AREA <- ggplot(data=condo_resale.sf, aes(x= `PROX_URA_GROWTH_AREA`)) +
  geom_histogram(bins=20, color="black", fill="light blue")
PROX_HAWKER_MARKET <- ggplot(data=condo_resale.sf, aes(x= `PROX_HAWKER_MARKET`)) +
  geom_histogram(bins=20, color="black", fill="light blue")
PROX_KINDERGARTEN <- ggplot(data=condo_resale.sf, aes(x= `PROX_KINDERGARTEN`)) +
  geom_histogram(bins=20, color="black", fill="light blue")
PROX_MRT <- ggplot(data=condo_resale.sf, aes(x= `PROX_MRT`)) +
  geom_histogram(bins=20, color="black", fill="light blue")
PROX_PARK <- ggplot(data=condo_resale.sf, aes(x= `PROX_PARK`)) +
  geom_histogram(bins=20, color="black", fill="light blue")
PROX_PRIMARY_SCH <- ggplot(data=condo_resale.sf, aes(x= `PROX_PRIMARY_SCH`)) +
  geom_histogram(bins=20, color="black", fill="light blue")
PROX_TOP_PRIMARY_SCH <- ggplot(data=condo_resale.sf, aes(x= `PROX_TOP_PRIMARY_SCH`)) +
  geom_histogram(bins=20, color="black", fill="light blue")


ggarrange(AREA_SQM, AGE, PROX_CBD, PROX_CHILDCARE, PROX_ELDERLYCARE, PROX_URA_GROWTH_AREA, PROX_HAWKER_MARKET, PROX_KINDERGARTEN, PROX_MRT, PROX_PARK, PROX_PRIMARY_SCH, PROX_TOP_PRIMARY_SCH, ncol = 4, nrow = 3)
```

## Statistical Point Map

Reveal the geospatial distribution condominium resale prices in Singapore.

set.zoom.limits argument of tm_view() sets the minimum and maximum zoom level to 11 and 14 respectively.

```{r}
tmap_mode("view")
tm_shape(mpsz_svy21)+
  tmap_options(check.and.fix = TRUE)+
  tm_polygons() +
tm_shape(condo_resale.sf) +  
  tm_dots(col = "SELLING_PRICE",
          alpha = 0.6,
          style="quantile") +
  tm_view(set.zoom.limits = c(11,14))
tmap_mode("plot")
```

## Hedonic Pricing Modelling in R

### Simple Linear Regression Method

Build a simple linear regression model by using SELLING_PRICE as the dependent variable and AREA_SQM as the independent variable.

lm() returns an object of class “lm” or for multiple responses of class c(“mlm”, “lm”).

```{r}
condo.slr <- lm(formula=SELLING_PRICE ~ AREA_SQM, data = condo_resale.sf)
```

summary() and anova() can be used to obtain and print a summary and analysis of variance table of the results. The generic accessor functions coefficients, effects, fitted.values and residuals extract various useful features of the value returned by lm.

```{r}
summary(condo.slr)
```

Analysis:

y = -258121.1 + 14719*AREA_SQM

R-squared: 0.4518 means the simple regression model built is able to explain about 45% of the resale prices.

p-value much smaller than 0.0001. Hence, we will reject the null hypothesis that mean is a good estimator of SELLING_PRICE. We can infer that simple linear regression model above is a good estimator of SELLING_PRICE.

Coefficient: p-values of both the estimates of the Intercept and ARA_SQM are smaller than 0.001. Hence, null hypothesis of B0 and B1 are equal to 0 are rejected. As a results, we can infer that the B0 and B1 are good parameter estimates.

```{r}
anova(condo.slr)
```

Visualise the best fit curve on a scatterplot, we can incorporate lm() as a method function in ggplot’s geometry

```{r}
ggplot(data=condo_resale.sf,  
       aes(x=`AREA_SQM`, y=`SELLING_PRICE`)) +
  geom_point() +
  geom_smooth(method = lm)
```

Analysis: There are a few outliers with high selling prices.

## Multiple Linear Regression Method

### Visualising the relationships of the independent variables

- important to ensure that indepedent variables used are not highly correlated to each other
- if highly correlated indepedent var are used, quality of the model will be compromised. (also known as multicollinearity)

corrplot package will be used to plot correlation matrix.

Plot a scatterplot matrix of the relationship between the independent variables in condo_resale data.frame

Matrix reorder methods: “AOE”, “FPC”, “hclust”, “alphabet”. "AOE" used

```{r fig.width=8, fig.height=8}
corrplot(cor(condo_resale[, 5:23]), diag = FALSE, order = "AOE",
         tl.pos = "td", tl.cex = 0.5, method = "number", type = "upper")
```

Analysis: Freehold is highly correlated to LEASE_99YEAR. Hence, to exclude one of them, LEASE_99YEAR.

### Building a hedonic pricing model using multiple linear regression method

```{r}
condo.mlr <- lm(formula = SELLING_PRICE ~ AREA_SQM + AGE  + PROX_CBD + PROX_CHILDCARE + PROX_ELDERLYCARE  + PROX_URA_GROWTH_AREA + PROX_HAWKER_MARKET  + PROX_KINDERGARTEN  + PROX_MRT  + PROX_PARK  + PROX_PRIMARY_SCH + PROX_TOP_PRIMARY_SCH + PROX_SHOPPING_MALL  + PROX_SUPERMARKET + PROX_BUS_STOP  + NO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD, data=condo_resale.sf)
summary(condo.mlr)
```

Analysis: Not all independent variables are statistically significant. To remove these variable (PROX_URA_GROWTH_AREA, PROX_HAWKER_MARKET, PROX_KINDERGARTEN, PROX_TOP_PRIMARY_SCH, PROX_SUPERMARKET)

Calibrate the revised model 

```{r}
condo.mlr1 <- lm(formula = SELLING_PRICE ~ AREA_SQM + AGE  + PROX_CBD + PROX_CHILDCARE + PROX_ELDERLYCARE  + PROX_URA_GROWTH_AREA + PROX_MRT  + PROX_PARK  + PROX_PRIMARY_SCH + PROX_SHOPPING_MALL  + PROX_BUS_STOP  + NO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD, data=condo_resale.sf)
ols_regress(condo.mlr1)
```

### Checking for multicolinearity

olsrr package provides a collection of very useful methods for building better multiple linear regression models:

- comprehensive regression output

- residual diagnostics

- measures of influence

- heteroskedasticity tests

- collinearity diagnostics

- model fit assessment

- variable contribution assessment

- variable selection procedures

test if there are sign of multicollinearity with ols_vif_tol

```{r}
ols_vif_tol(condo.mlr1)
```

VIF less than 10, there are no sign of multicolinearity among the independents variable

### Test for Non-Linearity

test the assumption that linearity and additivity of the relationship between dependent and independent variables

ols_plot_resid_fit() of olsrr package is used to perform linearity assumption test.

```{r}
ols_plot_resid_fit(condo.mlr1)
```

Analysis: The figure above shows that most data point are near 0 line. Hence, the relationship between dependent and independent variables are linear.

### Test for Normality Assumption

ols_plot_resid_hist() of olsrr package to perform normality assumption test.

```{r}
ols_plot_resid_hist(condo.mlr1)
```

Analysis: Residual of the multiple linear regression model resembles normal distribution.

statistical test methods with ols_test_normality() 

```{r}
ols_test_normality(condo.mlr1)
```

Analysis: p-values of the four tests are smaller than 0.05. Hence, we will reject the null hypothesis that the residual do resemble normal distribution.

### Testing for Spatial Autocorrelation

visualise the residual of the hedonic pricing model

To perform spatial autocorrelation test, we need to convert condo_resale.sf simple into a SpatialPointsDataFrame.

First, export the residual of the hedonic pricing model and save it as a data frame.

```{r}
mlr.output <- as.data.frame(condo.mlr1$residuals)
```

Next, join the newly created data frame with condo_resale.sf object.

```{r}
condo_resale.res.sf <- cbind(condo_resale.sf, 
                        condo.mlr1$residuals) %>%
rename(`MLR_RES` = `condo.mlr1.residuals`)
```

Next, convert condo_resale.res.sf simple feature object into a SpatialPointsDataFrame since spdep package can only process sp conformed spatial data objects.

```{r}
condo_resale.sp <- as_Spatial(condo_resale.res.sf)
condo_resale.sp
```

Next, use tmap o display the distribution of the residuals on an interactive map.

```{r}
tmap_mode("view")
tm_shape(mpsz_svy21)+
  tm_polygons(alpha = 0.4) +
tm_shape(condo_resale.res.sf) +  
  tm_dots(col = "MLR_RES",
          alpha = 0.6,
          style="quantile") +
  tm_view(set.zoom.limits = c(11,14))
tmap_mode("plot")
```

Analysis: There is a sign of spatial autocorrelation

Moran’s I test to proof that our observation is true

Compute the distance-based weight matrix by using dnearneigh() function of spdep.

```{r}
nb <- dnearneigh(coordinates(condo_resale.sp), 0, 1500, longlat = FALSE)
summary(nb)
```

Next, nb2listw() of spdep packge will be used to convert the output neighbours lists into a spatial weights.

```{r}
nb_lw <- nb2listw(nb, style = 'W')
summary(nb_lw)
```

Next, lm.morantest() of spdep package will be used to perform Moran’s I test for residual spatial autocorrelation

```{r}
lm.morantest(condo.mlr1, nb_lw)
```

Analysis: p-value is less than 0.05. Hence, we will reject the null hypothesis that the residuals are randomly distributed.

Observed Global Moran I = 0.1424418 is greater than 0, we can infer that the residuals resemble cluster distribution.

## Building Hedonic Pricing Models using GWmodel

### Building Fixed Bandwidth GWR Model

#### Computing fixed bandwith

bw.gwr() of GWModel package is used to determine the optimal fixed bandwidth to use in the model. adaptive set to False means we are interested to compute the fixed bandwidth.

Two possible apporach to determine stopping rule: CV, AIC

```{r}
bw.fixed <- bw.gwr(formula = SELLING_PRICE ~ AREA_SQM + AGE  + PROX_CBD + PROX_CHILDCARE + PROX_ELDERLYCARE  + PROX_URA_GROWTH_AREA + PROX_MRT  + PROX_PARK  + PROX_PRIMARY_SCH + PROX_SHOPPING_MALL  + PROX_BUS_STOP  + NO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD, data=condo_resale.sp, approach="CV", kernel="gaussian", adaptive=FALSE, longlat=FALSE)
```
### GWModel method - fixed bandwith

calibrate the gwr model using fixed bandwidth and gaussian kernel.

```{r}
gwr.fixed <- gwr.basic(formula = SELLING_PRICE ~ AREA_SQM + AGE  + PROX_CBD + PROX_CHILDCARE + PROX_ELDERLYCARE  + PROX_URA_GROWTH_AREA + PROX_MRT  + PROX_PARK  + PROX_PRIMARY_SCH + PROX_SHOPPING_MALL  + PROX_BUS_STOP  + NO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD, data=condo_resale.sp, bw=bw.fixed, kernel = 'gaussian', longlat = FALSE)
```

Output in list of class "gwrm"

```{r}
gwr.fixed
```

Analysis: Adjusted r-square of the gwr is 0.84 which is significantly better than the global multiple linear regression model of 0.6474.

### Building Adaptive Bandwidth GWR Model

#### Computing the adaptive bandwidth

Similar to fixed bandwidth, but adaptive is TRUE.

```{r}
bw.adaptive <- bw.gwr(formula = SELLING_PRICE ~ AREA_SQM + AGE  + PROX_CBD + PROX_CHILDCARE + PROX_ELDERLYCARE  + PROX_URA_GROWTH_AREA + PROX_MRT  + PROX_PARK  + PROX_PRIMARY_SCH + PROX_SHOPPING_MALL  + PROX_BUS_STOP  + NO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD, data=condo_resale.sp, approach="CV", kernel="gaussian", adaptive=TRUE, longlat=FALSE)
```

Analysis: 30 is the recommended data point

#### Constructing the adaptive bandwidth gwr model

```{r}
gwr.adaptive <- gwr.basic(formula = SELLING_PRICE ~ AREA_SQM + AGE  + PROX_CBD + PROX_CHILDCARE + PROX_ELDERLYCARE  + PROX_URA_GROWTH_AREA + PROX_MRT  + PROX_PARK  + PROX_PRIMARY_SCH + PROX_SHOPPING_MALL  + PROX_BUS_STOP  + NO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD, data=condo_resale.sp, bw=bw.adaptive, kernel = 'gaussian', adaptive=TRUE, longlat = FALSE)
```

```{r}
gwr.adaptive
```

Analysis: Adjusted r-square of the gwr is 0.856 which is significantly better than the global multiple linear regression model of 0.6474

## Converting SDF into sf data.frame

To visualise the fields in SDF, need to first covert it into sf data.frame

```{r}
condo_resale.sf.adaptive <- st_as_sf(gwr.adaptive$SDF) %>%
  st_transform(crs=3414)
```

```{r}
condo_resale.sf.adaptive.svy21 <- st_transform(condo_resale.sf.adaptive, 3414)
condo_resale.sf.adaptive.svy21  
```

```{r}
gwr.adaptive.output <- as.data.frame(gwr.adaptive$SDF)
condo_resale.sf.adaptive <- cbind(condo_resale.res.sf, as.matrix(gwr.adaptive.output))
```


```{r}
glimpse(condo_resale.sf.adaptive)
```

```{r}
summary(gwr.adaptive$SDF$yhat)
```

## Visualising local R2

```{r}
tmap_mode("view")
tm_shape(mpsz_svy21)+
  tm_polygons(alpha = 0.1) +
tm_shape(condo_resale.sf.adaptive) +  
  tm_dots(col = "Local_R2",
          border.col = "gray60",
          border.lwd = 1) +
  tm_view(set.zoom.limits = c(11,14))
tmap_mode("plot")
```

## By URA Plannign Region

```{r}

tm_shape(mpsz_svy21[mpsz_svy21$REGION_N=="CENTRAL REGION", ])+
  tm_polygons()+
tm_shape(condo_resale.sf.adaptive) + 
  tm_bubbles(col = "Local_R2",
           size = 0.15,
           border.col = "gray60",
           border.lwd = 1)
```

